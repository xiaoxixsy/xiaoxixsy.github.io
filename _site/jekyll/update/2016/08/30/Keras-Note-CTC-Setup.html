<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Keras Learning Note: Speech Recognition CTC Setup</title>
  <meta name="description" content="Running CTC Network using keras">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://atlantix.com/jekyll/update/2016/08/30/Keras-Note-CTC-Setup.html">
  <link rel="alternate" type="application/rss+xml" title="Jianjing Xu's Blog" href="http://atlantix.com/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Jianjing Xu's Blog</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Keras Learning Note: Speech Recognition CTC Setup</h1>
    <p class="post-meta"><time datetime="2016-08-30T16:03:23+08:00" itemprop="datePublished">Aug 30, 2016</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h2 id="running-ctc-network-using-keras">Running CTC Network using keras</h2>

<p>Keras has just merged a request containing batch CTC loss function. Although it contains an example code, but it is an image OCR program, and it is quite hard to read… This new coming functionality does not have a good documentation and code example, having costed me nearly two week before get my CTC network to working. Well now I will not bother to mention those unhappy days.</p>

<p>Network definition: ( You can read the code beginning from <code class="highlighter-rouge">FrameInput</code>, and you most essential part starts from <code class="highlighter-rouge">ctc_loss_out</code>)</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">ctc_lambda_func</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">label_length</span> <span class="o">=</span> <span class="n">args</span>
    <span class="c"># the 2 is critical here since the first couple outputs of the RNN</span>
    <span class="c"># tend to be garbage:</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:,</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">ctc_batch_cost</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">label_length</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ConvCTCDiLSTM</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s">"""
    Enabling CTC training on convolution and Deep bidirectional LSTM network
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"ConvCTCLSTM"</span><span class="p">,</span><span class="n">maxif</span><span class="o">=</span><span class="mi">405</span><span class="p">,</span><span class="n">maxil</span><span class="o">=</span><span class="mi">74</span><span class="p">,</span><span class="n">conv_fnum</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span><span class="n">conv_t</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">conv_f</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">pool_t</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">pool_f</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_phonemes</span><span class="o">=</span><span class="mi">39</span><span class="p">,</span><span class="n">featuresize</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">weight_path</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">ifFT</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">optimi</span><span class="o">=</span><span class="s">'Adam'</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]):</span>
        <span class="s">"""
        @param maxif the max length of input frame
        @param maxil the max length of phoneme sequence
        @param convf_num Convolution filter number of the first layer. But I set each deeper layer is double the size of the previous one
        @param conv_t time axis' expand of convolution
        @param conv_f frequency axis' expand of convolution
        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">optimi</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxif</span> <span class="o">=</span> <span class="n">maxif</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxil</span> <span class="o">=</span> <span class="n">maxil</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">maxil</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"CTC_Label"</span><span class="p">)</span>
        <span class="c"># Input to CTC: the network's prediction length</span>
        <span class="n">input_length</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="s">'int32'</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"input_length"</span><span class="p">)</span>
        <span class="c"># Input to CTC: length of sequence.</span>
        <span class="n">label_length</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="s">'int32'</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"label_length"</span><span class="p">)</span>
        <span class="c"># Original structure</span>
        <span class="n">FrameInput</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">maxif</span><span class="p">,</span><span class="n">featuresize</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"Framewise_Input"</span><span class="p">)</span>

        <span class="n">Conv1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Convolution2D</span><span class="p">(</span><span class="n">conv_fnum</span><span class="p">,</span><span class="n">conv_t</span><span class="p">,</span><span class="n">conv_f</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s">'valid'</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="s">"tanh"</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">maxif</span><span class="p">,</span><span class="n">featuresize</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">'conv1'</span><span class="p">)(</span><span class="n">FrameInput</span><span class="p">)</span>
        <span class="n">len2</span> <span class="o">=</span> <span class="n">maxif</span> <span class="o">-</span> <span class="n">conv_t</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">h2</span> <span class="o">=</span> <span class="n">featuresize</span> <span class="o">-</span> <span class="n">conv_f</span> <span class="o">+</span><span class="mi">1</span>
        <span class="n">Conv2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Convolution2D</span><span class="p">(</span><span class="n">conv_fnum</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span><span class="n">conv_t</span><span class="p">,</span><span class="n">h2</span><span class="p">,</span><span class="n">border_mode</span><span class="o">=</span><span class="s">'valid'</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="s">'tanh'</span><span class="p">,</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">conv_fnum</span><span class="p">,</span><span class="n">len2</span><span class="p">,</span><span class="n">h2</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s">'conv2'</span><span class="p">)(</span><span class="n">Conv1</span><span class="p">)</span>
        <span class="c"># output shape: (samples,conv_fnum * 2, len2 -conv_t+1 ,1)</span>

        <span class="n">rnn_shape</span> <span class="o">=</span> <span class="p">(</span> <span class="n">conv_fnum</span> <span class="o">*</span> <span class="mi">2</span> <span class="p">,</span> <span class="n">len2</span> <span class="o">-</span> <span class="n">conv_t</span> <span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="c"># input_len is the input length of CTC, i.e.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_len</span> <span class="o">=</span> <span class="n">rnn_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c"># The main role of reshape is to change 3D output into 2D input</span>
        <span class="n">Reshape_1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="n">rnn_shape</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"Reshape_1"</span><span class="p">)(</span><span class="n">Conv2</span><span class="p">)</span>
        <span class="c"># Permute is used to switch axis.</span>
        <span class="n">Permute_1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Permute</span><span class="p">(</span><span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s">"Permute_1"</span><span class="p">)(</span><span class="n">Reshape_1</span><span class="p">)</span>
        <span class="n">DenseToRNN</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">))(</span><span class="n">Permute_1</span><span class="p">)</span>

        <span class="n">FLSTM_1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">'Forward_LSTM_1'</span><span class="p">)(</span><span class="n">DenseToRNN</span><span class="p">)</span>
        <span class="n">FLSTM_2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">'Forward_LSTM_2'</span><span class="p">)(</span><span class="n">FLSTM_1</span><span class="p">)</span>
        <span class="n">BLSTM_1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span><span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"Backward_LSTM_1"</span><span class="p">)(</span><span class="n">DenseToRNN</span><span class="p">)</span>
        <span class="n">BLSTM_2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span><span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"Backward_LSTM_2"</span><span class="p">)(</span><span class="n">BLSTM_1</span><span class="p">)</span>
        <span class="n">merge1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">merge</span><span class="p">([</span><span class="n">FLSTM_2</span><span class="p">,</span><span class="n">BLSTM_2</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s">'concat'</span><span class="p">)</span>
        <span class="n">dense</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_phonemes</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="p">)(</span><span class="n">merge1</span><span class="p">)</span>

        <span class="n">FramePred</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'softmax'</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">'Softmax'</span><span class="p">)(</span><span class="n">dense</span><span class="p">)</span>

        <span class="n">ctc_loss_out</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="n">ctc_lambda_func</span><span class="p">,</span><span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span><span class="n">name</span><span class="o">=</span><span class="s">"CTC_Loss"</span><span class="p">)([</span><span class="n">FramePred</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">input_length</span><span class="p">,</span><span class="n">label_length</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="p">[</span><span class="n">FrameInput</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">input_length</span><span class="p">,</span><span class="n">label_length</span><span class="p">],</span><span class="n">output</span><span class="o">=</span><span class="p">[</span><span class="n">ctc_loss_out</span><span class="p">])</span>

        <span class="n">model_def</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="o">.</span><span class="n">to_json</span><span class="p">()</span>
        <span class="nb">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="o">+</span><span class="s">"</span><span class="err">\</span><span class="s">_model_def.json"</span><span class="p">,</span><span class="s">"w"</span><span class="p">)</span>
        <span class="nb">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">model_def</span><span class="p">)</span>
        <span class="nb">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">weight_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Loading model from file."</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">weight_path</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">keras_model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">{</span><span class="s">'CTC_Loss'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">FramePred</span><span class="p">:</span> <span class="n">FramePred</span><span class="p">},</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">"Adadelta"</span><span class="p">)</span></code></pre></figure>

<p>As you can see if you have already read example code <code class="highlighter-rouge">image_ocr.py</code>, the core code is almost the same. Well, I have to confess that I waste a lot of time on using <code class="highlighter-rouge">K.ctc_cost</code> rather than batch cost. Because the glimpse of the example code gave me the impression that I have to pad the sequence. As CTC it self contains the combination of repeating predictions, it is quite unacceptable to interpret a single block of silence into a few continuous label sequence. But later I came to realize that in batch cost, the program managed to mask out padded sequence using <code class="highlighter-rouge">label_length</code>, so I returned to use batch cost.
But even though the code is almost the same as example, there are still few more traps if you start from the example code. Well, I will tell you about this later, let’s get back onto the correct one now.</p>

<p>The motivation of the core code can be summed up as followings:</p>

<ul>
  <li>Giving framewise prediction and label sequence as well as their corresponding length to <code class="highlighter-rouge">ctc_batch_cost</code> function.</li>
  <li>Incorporate the theano function into keras network by <code class="highlighter-rouge">Lambda</code> layer.</li>
  <li>Compile the model using dummy loss.</li>
</ul>

<p>In fact, I am not aware of how the loss is calculated, so I don’t know why I have to set the loss in this way. Maybe I have to go through <code class="highlighter-rouge">compile</code> in keras. As stated by the original author, the actual loss calculation happens elsewhere and this loss is for completion.<br />
So we just need to pass the data as required.</p>

<p>Data preprocessing and training configuation:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">BatchTrainingScheduler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s">"""
    Schedule batch training of CTC network.
    Maybe more generally in the future
    """</span>
    <span class="c">### model is a keras model</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">name</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">ph_Y</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="n">epoch</span><span class="p">):</span>
        <span class="s">"""
        Take in the full dataset and desired epoch number, schedule a batch-based training and evaluation.
        This class is optimized for keras' 4D training data.
        i.e. X : (samples,channel,length,feature)
            Y : (samples,length,n_class)
        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ph_Y</span> <span class="o">=</span> <span class="n">ph_Y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tot_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Net</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

    <span class="c">### Train for one epoch</span>
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">bi</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">ei</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c"># i is batch index</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_num</span><span class="p">):</span>
            <span class="n">bi</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="n">ei</span> <span class="o">=</span> <span class="n">bi</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="k">if</span> <span class="n">ei</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="n">ei</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">train_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">bi</span><span class="p">:</span><span class="n">ei</span><span class="p">,:,:,:]</span>
            <span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Net</span><span class="o">.</span><span class="n">maxil</span><span class="p">))</span>
            <span class="n">len_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">bi</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ei</span><span class="o">-</span><span class="n">bi</span><span class="p">)])</span>
            <span class="n">len_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">Net</span><span class="o">.</span><span class="n">input_len</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)])</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">train_y</span><span class="p">[</span><span class="n">j</span><span class="p">,:</span><span class="n">len_y</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">bi</span><span class="o">+</span><span class="n">j</span><span class="p">][:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"int32"</span><span class="p">)</span>

            <span class="c">#print(len_pred)</span>
            <span class="c">#print(len_y)</span>
            <span class="c">#print(train_x.shape)</span>
            <span class="c">#print(train_y.shape)</span>

            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Net</span><span class="o">.</span><span class="n">keras_model</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">({</span><span class="s">"CTC_Label"</span><span class="p">:</span><span class="n">train_y</span><span class="p">,</span><span class="s">"Framewise_Input"</span><span class="p">:</span><span class="n">train_x</span><span class="p">,</span><span class="s">"label_length"</span><span class="p">:</span><span class="n">len_y</span><span class="p">,</span><span class="s">"input_length"</span><span class="p">:</span><span class="n">len_pred</span><span class="p">},</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">train_y</span><span class="p">))</span>
            <span class="k">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Training for </span><span class="si">%</span><span class="s">d epoches"</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">tot_epoch</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tot_epoch</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Epoch </span><span class="si">%</span><span class="s">d:"</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Shuffling data..."</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ph_Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">shuffle_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">ph_Y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">)</span></code></pre></figure>

<p>And here comes the most tricky step, which trapped me for nearly one week:</p>

<h2 id="export-theanoflagsoptimizerfastcompile">export THEANO_FLAGS=optimizer=fast_compile</h2>

<p>Well,it may not be a indispensible one. After I experimented on more machines, I found the need for this flag vary with machine and even model scale. For example, constructing a 2-layer bi-directional LSTM will require this flag in one machine while 1-layer will not. And in my personal laptop (which is CPU-only) all the model require settting this flag.</p>

<p>It is quite an unbelievable setting. Maybe I have not really cleared the bugs. Setting the <code class="highlighter-rouge">optimizer</code> configuration involved with Theano graph optimization. This configuration is <code class="highlighter-rouge">fast_run</code> by default. Setting this flag to fast_compile or None both works. If you try to compile the model normally, you will face the following bugs:</p>

<ul>
  <li>The model cannot compile in stacking the second layer of LSTM.</li>
  <li>(If you reduce the model to one layer of BiLSTM) Theano will report <code class="highlighter-rouge">scan</code> using regative index (perhaps -37)</li>
</ul>

<p>Unbelievable. You may imagine the how a Theano and Keras beginner feels when he tried for tens of times and confirmed this issue. Please help me if you have any idea. I’d better write my code for another time before I assume it is a bug of Theano :) .
## But, it works.
### And I would be grateful if you can tell me why.</p>

<p>Any way, using the following configuration, it is expected to setup CTC training.
But there is still one problem: Training tend to produce <code class="highlighter-rouge">nan</code> after a few iteration. And it is quite stochastic. If you use SGD with learning rate<code class="highlighter-rouge">0.001</code>, you will get <code class="highlighter-rouge">nan</code> after about 15 iterations. If you use <code class="highlighter-rouge">0.0001</code> SGD, <code class="highlighter-rouge">nan</code> will appear  in 100 iteration. If you use <code class="highlighter-rouge">Adadelta</code> or <code class="highlighter-rouge">Adam</code>, loss will quickly go down to about 800 but then become <code class="highlighter-rouge">nan</code>.</p>

<p>Currently, if you are training a model similar to my model shown above, you should set learning rate to <code class="highlighter-rouge">10-6</code> (for about 64 convolution filters). If you use single layer BLSTM, then <code class="highlighter-rouge">10-5</code> is ok.</p>

<p>To sum up, though keras provide a convenient solution for regular network configuration, we have to use more fundamental toolkits such as Theano if we need to train unusual networks. For the next few days, I will dive into using <code class="highlighter-rouge">raw</code> theano to build a CTC network.</p>

<p>If you use the code or this post elsewhere, please show the credit :)</p>

  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Jianjing Xu's Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Jianjing Xu's Blog</li>
          <li><a href="mailto:xujj15@mails.tsinghua.edu.cn">xujj15@mails.tsinghua.edu.cn</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/AtlantixJJ"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">AtlantixJJ</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/Non"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">Non</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Some day my AI will help me write the blogs...
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
