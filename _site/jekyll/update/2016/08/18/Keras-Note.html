<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Keras Learning Note: Framewise RNN Setup and Convolution integration</title>
  <meta name="description" content="Step-by-step introduction of Framewise RNN in Keras">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://atlantix.com/jekyll/update/2016/08/18/Keras-Note.html">
  <link rel="alternate" type="application/rss+xml" title="Jianjing Xu's Blog" href="http://atlantix.com/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Jianjing Xu's Blog</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Keras Learning Note: Framewise RNN Setup and Convolution integration</h1>
    <p class="post-meta"><time datetime="2016-08-18T16:03:23+08:00" itemprop="datePublished">Aug 18, 2016</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h2 id="step-by-step-introduction-of-framewise-rnn-in-keras">Step-by-step introduction of Framewise RNN in Keras</h2>

<p>Take Speech Recognition as example, RNN takes in frame input and produce framewise output. Using keras, this can be achieved with minimal code. But there is a shortcoming of using keras, that all input frame need to be of the same length to enable batch training. You will have to use <code class="highlighter-rouge">keras.preprocessing.sequence.pad_sentence</code> method to get your data ready for batch training. If you are disgusted by padding, you will get to know how to train with <code class="highlighter-rouge">batchsize=1</code> without padding at the end of this blog.</p>

<h3 id="data-preparation">Data Preparation</h3>

<p>First of all, let’s get onto data preparation. Well, I will take Speech Recognition as example again. Now you have a <code class="highlighter-rouge">.wav</code> audio file which you have loaded into memory and converted into frequency spectrum. ( You can refer to <a href="https://github.com/jameslyons/python_speech_features">python speech feature</a> if you don’t know how to complete the step above.) The spectrum is a 2-dim array which is expected to have the shape <code class="highlighter-rouge">(FrameLength,FeatureSize)</code>. Using keras’ interface make it easy to adjust the length of training sequences.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># Train_data is a list of spectrums</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">sequence</span>
<span class="n">Train_data</span> <span class="o">=</span> <span class="n">sequence</span><span class="o">.</span><span class="n">pad_sentence</span><span class="p">(</span><span class="n">Train_data</span><span class="p">)</span>
<span class="c"># Now Train_data is 3D numpy ndarray type</span></code></pre></figure>

<p>Keras’ <code class="highlighter-rouge">models.fit</code> method expect training data with format <code class="highlighter-rouge">numpy.ndarray</code> and shape <code class="highlighter-rouge">(sample,length,feature)</code>. As for label, in case you want to use <code class="highlighter-rouge">cross_entropy</code> loss, you will need to transform the label into  probability-distribution-like target like the figure below.
<img src="/assets/seg.png" alt="Segmentation" /></p>

<p>Now the data preparation is done! If you have your model properly built, you can then call fit method to train your net.
So let’s get onto the network building. Give a glance at keras’ LSTM examples and you will find that similar code won’t work for framewise predictions.
For example, <code class="highlighter-rouge">imdb_lstm.py</code>, the simplest one:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">max_features</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">dropout_W</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dropout_U</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>  <span class="c"># try using a GRU instead, for fun</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s">'sigmoid'</span><span class="p">))</span></code></pre></figure>

<p>IMDB is a widely used dataset for various purpose. Here it is used to classify emotion. So the example takes in a sequence and produce a single scalar as output. As for <code class="highlighter-rouge">Embedding</code>, it is a layer for transforming a scalar presentation (e.g. no. of vocabulary) into another vector representation with different dimension. This example looks quite simple but it is far from what we need to handle.
Just think about it, how can a normally placed <code class="highlighter-rouge">Dense</code> layers be aware of the time axis?
So the trick here is to use <code class="highlighter-rouge">layers.TimeDistributed</code> on Dense layers. Like this:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_class</span><span class="p">)))</span></code></pre></figure>

<p>As expected, our simple net compiles.</p>

<h3 id="make-your-model-deep-and-bi-directional">Make your model deep and bi-directional</h3>
<p>You may consider stacking RNN or LSTM. And make bi-directional RNNs, which is quite popular in recent literatures.
To enable bi-directional RNN is quite simple. Just initialize with <code class="highlighter-rouge">go_backwards=True</code> and stack the layers together. Keras’ example code gives quite a clear example:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">forwards</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">)(</span><span class="n">embedded</span><span class="p">)</span>
<span class="c"># apply backwards LSTM</span>
<span class="n">backwards</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">)(</span><span class="n">embedded</span><span class="p">)</span>
<span class="c"># concatenate the outputs of the 2 LSTMs</span>
<span class="n">merged</span> <span class="o">=</span> <span class="n">merge</span><span class="p">([</span><span class="n">forwards</span><span class="p">,</span> <span class="n">backwards</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s">'concat'</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="c"># or mode='sum'</span>
<span class="n">after_dp</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">merged</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">)(</span><span class="n">after_dp</span><span class="p">)</span></code></pre></figure>

<p>But there is a pitfall with deep bi-directional networks. You have to enable <code class="highlighter-rouge">return_sequences</code> or Recurrent layer will simply return single result rather than framewise output. In addition, one problem confused me for a long time. Whether shall we enable <code class="highlighter-rouge">go_backwards</code> is deep backward RNN?</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">forward1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)(</span><span class="n">Input</span><span class="p">)</span>
<span class="n">forward2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)(</span><span class="n">forward1</span><span class="p">)</span>
<span class="n">backward1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span><span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)(</span><span class="n">Input</span><span class="p">)</span>
<span class="c"># Aha, which one should you choose?</span>
<span class="k">if</span> <span class="n">bw</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">backward2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span><span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)(</span><span class="n">backward1</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">backward2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)(</span><span class="n">backward1</span><span class="p">)</span></code></pre></figure>

<p>If you dive into keras’ code, you will find the related core source code is in <code class="highlighter-rouge">theano_backend.py</code>. Let’s take a close look at the the backwards related part. Notice that this part contains some duplicated code for different situations like mask or unroll, which is surely identical in terms of backwards computation.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">_step</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="o">*</span><span class="n">states</span><span class="p">):</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">new_states</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">states</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">output</span><span class="p">]</span> <span class="o">+</span> <span class="n">new_states</span>

<span class="n">results</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span>
    <span class="n">_step</span><span class="p">,</span>
    <span class="n">sequences</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
    <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">initial_states</span><span class="p">,</span>
    <span class="n">non_sequences</span><span class="o">=</span><span class="n">constants</span><span class="p">,</span>
    <span class="n">go_backwards</span><span class="o">=</span><span class="n">go_backwards</span><span class="p">)</span>
    <span class="c"># giving backwards to theano.scan make the input sequence just the reverse.</span>

<span class="c"># deal with Theano API inconsistency</span>
<span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">states</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">results</span>
    <span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
<span class="n">last_output</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">dimshuffle</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
<span class="n">states</span> <span class="o">=</span> <span class="p">[</span><span class="n">T</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">states</span><span class="p">]</span>
<span class="k">return</span> <span class="n">last_output</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">states</span></code></pre></figure>

<p>So now we can see that keras did not reverse the output sequence. As suggest by https://github.com/fchollet/keras/issues/3448, we need to add reverse layer manually.
Alternatively, we can stack two <code class="highlighter-rouge">go_backwards</code> together…
Adding <code class="highlighter-rouge">go_backwards</code> or not does not affect the computational efficiency, since this operation is simply a twist of input! For deep RNNs, they always complete a whole layer’s computation before they progress into deeper ones. Gradient computation is similar to this. As a result, the training speed of both versions is almost the same, which I have confirmed on TIMIT dataset.</p>

<p>In addition, I have to say that this version of deep bi-directional RNN is not a popuplar one. Rather I would like to call it bi-directional deep RNN. Most DBRNN combine their output after one layer, which mixes forward information and backward information quickly. While I propose that stacking deeper before forward and backward information mixes is prone to improve representational power of uniform direction. And we just need to combine forward and backward feature with a shallow architecture. In this way, the network has a clearer structure.</p>

<h2 id="incorporate-convolution-with-lstm">Incorporate Convolution with LSTM</h2>
<p>Using RNN only is rather simple as it is like utilizing a standard model. But adding a convolution layer requires more techniques and tries.
To achieve this, you have a bunch of tips to know in priority (which takes tens of tries for me to realize them):
+ Convolution assumes a 3D input shape setting. ( Maybe 4D actually). So input shape is fixed in any way.
+ Though input shape is fixed, parameters can be loaded (finetuned) for different input shape. This make it possible for changing length.
+ Between convolution output and LSTM input, you need to <code class="highlighter-rouge">reshape</code> and <code class="highlighter-rouge">permute</code>.
+ Be really careful about output shapes. You have to compute reshape’s shape, convolution’s input and output shape manually.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="s">"""
@param maxif the max length of input frame
@param convf_num Convolution filter number of the first layer. But I set each deeper layer is double the size of the previous one
@param conv_t time axis' expand of convolution
@param conv_f frequency axis' expand of convolution
"""</span>
<span class="n">FrameInput</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">maxif</span><span class="p">,</span><span class="n">featuresize</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"Framewise_Input"</span><span class="p">)</span>

<span class="n">Conv1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Convolution2D</span><span class="p">(</span><span class="n">conv_fnum</span><span class="p">,</span><span class="n">conv_t</span><span class="p">,</span><span class="n">conv_f</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s">'valid'</span><span class="p">,</span>
<span class="n">activation</span><span class="o">=</span><span class="s">"tanh"</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">maxif</span><span class="p">,</span><span class="n">featuresize</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">'conv1'</span><span class="p">)(</span><span class="n">FrameInput</span><span class="p">)</span>
<span class="n">len2</span> <span class="o">=</span> <span class="n">maxif</span> <span class="o">-</span> <span class="n">conv_t</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">h2</span> <span class="o">=</span> <span class="n">featuresize</span> <span class="o">-</span> <span class="n">conv_f</span> <span class="o">+</span><span class="mi">1</span>
<span class="n">Conv2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Convolution2D</span><span class="p">(</span><span class="n">conv_fnum</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span><span class="n">conv_t</span><span class="p">,</span><span class="n">h2</span><span class="p">,</span><span class="n">border_mode</span><span class="o">=</span><span class="s">'valid'</span><span class="p">,</span>
<span class="n">activation</span><span class="o">=</span><span class="s">'tanh'</span><span class="p">,</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">conv_fnum</span><span class="p">,</span><span class="n">len2</span><span class="p">,</span><span class="n">h2</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s">'conv2'</span><span class="p">)(</span><span class="n">Conv1</span><span class="p">)</span>
<span class="c"># output shape: (samples,conv_fnum * 2, len2 -conv_t+1 ,1)</span>

<span class="n">rnn_shape</span> <span class="o">=</span> <span class="p">(</span> <span class="n">conv_fnum</span> <span class="o">*</span> <span class="mi">2</span> <span class="p">,</span> <span class="n">len2</span> <span class="o">-</span> <span class="n">conv_t</span> <span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="c"># input_len is the input length of CTC, i.e.</span>
<span class="bp">self</span><span class="o">.</span><span class="n">input_len</span> <span class="o">=</span> <span class="n">rnn_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="c"># The main role of reshape is to change 3D output into 2D input</span>
<span class="n">Reshape_1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="n">rnn_shape</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"Reshape_1"</span><span class="p">)(</span><span class="n">Conv2</span><span class="p">)</span>
<span class="c"># Permute is used to switch axis.</span>
<span class="n">Permute_1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Permute</span><span class="p">(</span><span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s">"Permute_1"</span><span class="p">)(</span><span class="n">Reshape_1</span><span class="p">)</span>
<span class="n">DenseToRNN</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">))(</span><span class="n">Permute_1</span><span class="p">)</span>

<span class="n">FLSTM_1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">'Forward_LSTM_1'</span><span class="p">)(</span><span class="n">DenseToRNN</span><span class="p">)</span>
<span class="n">FLSTM_2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">'Forward_LSTM_2'</span><span class="p">)(</span><span class="n">FLSTM_1</span><span class="p">)</span>
<span class="n">BLSTM_1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span><span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"Backward_LSTM_1"</span><span class="p">)(</span><span class="n">DenseToRNN</span><span class="p">)</span>
<span class="n">BLSTM_2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">conv_fnum</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span><span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">"Backward_LSTM_2"</span><span class="p">)(</span><span class="n">BLSTM_1</span><span class="p">)</span>
<span class="n">merge1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">merge</span><span class="p">([</span><span class="n">FLSTM_2</span><span class="p">,</span><span class="n">BLSTM_2</span><span class="p">],</span><span class="n">mode</span><span class="o">=</span><span class="s">'concat'</span><span class="p">)</span>
<span class="n">dense</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_phonemes</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="p">)(</span><span class="n">merge1</span><span class="p">)</span>

<span class="n">FramePred</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'softmax'</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">'Softmax'</span><span class="p">)(</span><span class="n">dense</span><span class="p">)</span></code></pre></figure>

<p>Well, I think I make it quite clear in the comments. In summary, the main difficulties for new beginners is just the four points mentioned above.
I have trained my neural network on TIMIT, but it seemed quite strange that it overfits heavily. On training set, I achieved frame accuracy of 95% but on core test set it was only 45%. Even if I cut down the network to 32 convolution filters ( 128 for LSTMs), the result was almost the same. Well, for overfitting problems, one is expected to add weight regularization terms and enlarge training set. So I applied the following enhancement:
<img src="/assets/TIMIT_concate.png" alt="Concatenated Input data" />
+ Enlarged the dataset for almost one time larger by downsampling the wav files (from 16000K to 8000K). For human ears, the downsampled voice become a little bit vague but it is recognizable.
+ Stochastically concatenated utterances.
The code is running on GPUs right now. And a few days later you can see the report.</p>

<p>To sum up, this is how I setup a framewise RNN integrated with CNN. In those days, I really had a hard time figuring out problems which seems nothing to me right now. If I have any mistake, please point it out for me, as I am no more than a new learner.  Hope this blog can help you save the time that I once wasted.</p>

<p>Please give the credit to the original author if you use it elsewhere.</p>

<p>Jianjing, Xu.
Atlantix.
Department of Computer Science, Tsinghua University.</p>

  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Jianjing Xu's Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Jianjing Xu's Blog</li>
          <li><a href="mailto:xujj15@mails.tsinghua.edu.cn">xujj15@mails.tsinghua.edu.cn</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/AtlantixJJ"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">AtlantixJJ</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/Non"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">Non</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Some day my AI will help me write the blogs...
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
